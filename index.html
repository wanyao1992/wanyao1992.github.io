<!DOCTYPE html>
<html lang="en" xml:lang="en">
   <head>
      <title>Yao Wan@Huazhong University of Science and Technology</title>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="chrome=1">
      <meta name="viewport" content="width=device-width initial-scale=1.0">
      <link rel="stylesheet" href="lib/bootstrap-3.3.7-dist/css/bootstrap.min.css">
      <link href="assets/bootstrap/css/bootstrap.min.css" rel="stylesheet">
      <link rel="stylesheet" href="lib/font-awesome-4.7.0-2/css/font-awesome.min.css">
      <link rel="stylesheet" href="lib/academicons-1.8.6-2/css/academicons.min.css">
      <link href="assets/style.css" rel="stylesheet">
      <link rel="stylesheet" href="stylesheets/styles.css">
      <link rel="stylesheet" href="stylesheets/pub-styles.css">
      <link rel="stylesheet" href="stylesheets/lz.css">

      <!-- [if lt IE 9]
         <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
         [endif] -->
      <!-- Global site tag (gtag.js) - Google Analytics -->
      <link rel="shortcut icon" href="img/icons/favicon.png"/>
   </head>
   <div class="container">
     <!-- ======= Header ======= -->
     <header id="header"> <!--class="fixed-top"-->
       <div class="d-flex align-items-center">
         <h1 class="logo mr-auto"><a></a></h1>
         <!-- Uncomment below if you prefer to use an image logo -->
         <!-- <a href="index.html" class="logo mr-auto"><img src="assets/img/logo.png" alt="" class="img-fluid"></a>-->
         <nav class="nav-menu d-lg-block">
           <ul>
             <li class="active"><a href="index.html">Home</a></li>
             <li><a href="publication.html">Publications</a></li>
             <li><a href="student.html">Students</a></li>
             <li><a href="https://oneslab.github.io/">ONE Lab</a></li>
           </ul>
         </nav><!-- .nav-menu -->

         <!-- <a href="#about" class="get-started-btn scrollto">Get Started</a> -->

       </div>
     </header><!-- End Header -->
     <!-- <div class="prebody">
         <div class="box">
            <h1 class="text">Welcome to the</h1>
            <div class="flex">
               <div class="icon">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="-40 -60 80 100">
                     <style>
                       .bubble {
                         animation: float 2s ease-out both infinite var(--delay);
                       }
                       @keyframes float {
                         0% {
                           opacity: 0;
                         }
                         50% {
                           transform: translateY(0);
                           opacity: 0;
                         }
                         75% {
                           opacity: 1;
                         }
                         100% {
                           opacity: 0;
                           transform: translateY(-40px);
                         }
                       }
                     </style>
                     <g fill="currentColor" opacity="0.5">
                       <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 0.1s"></circle>
                       <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 0.4s"></circle>
                       <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 1.1s"></circle>
                     </g>
                     <path fill="#38bdf8" d="
                         M 0 -22.5
                         L -19.5 -11.25
                         L -19.5 11.25
                         L 0 22.5
                         L 19.5 11.25
                         L 19.5 -11.25
                         z
                       "></path>
                     <path fill="#bae6fd" d="
                         M 0 -22.5
                         L -19.5 -11.25
                         L 0 0
                         L 19.5 -11.25
                         z
                       "></path>
                     <path fill="none" stroke="currentColor" stroke-width="5" d="
                         M -18 -53
                         L -10 -53
                         L -10 -29.2
                         L -30.3 -17.5
                         L -30.3 17.5
                         L 0 35
                         L 30.3 17.5
                         L 30.3 -17.5
                         L 10 -29.2
                         L 10 -53
                         L 18 -53
                       "></path>
                   </svg>
               </div>
               <h1 class="name">Ones Lab</h1>
            </div>
            
         </div>
     </div> -->
   <body>
         <div class="row body">
            <div class="side-bar col-md-4 col-sm-12 col-xs-12">
               <div class="side-bar-panel">
                  <div>
                      <h1><span class="english-name">Yao Wan</span>&nbsp;&nbsp;&nbsp;<span lang="zh-Hant" class="chinese-name">萬瑤</span></h1>
                     <div class="row name-card">
                        <div class="col-md-6 col-sm-3 col-xs-5">
                           <img src="img/yaowan-homepage.png" alt="Sketch of me" class="img-circle img-responsive">
                        </div>
                        <div class="col-md-6 col-sm-9 col-xs-7 contacts">
                          <div class="title">
                              Assoc. Prof.@HUST<br>
                              <!-- HUST<br> -->
                          </div>
                          <div class="address"><i class="fa fa-map-marker" aria-hidden="true"></i>
                           1037 Luoyu Road, Wuhan, Hubei, China<br>
                          </div>
                          <div class="email">
                            <i class="fa fa-envelope" aria-hidden="true"></i> <a href="mailto:wanyao{AT}hust.edu.cn" style="font-family: Lato, sans-serif; font-weight: 400">wanyao@hust.edu.cn</a>
                          </div>
                          <div class="social-networks">
                            <a href="https://scholar.google.com/citations?user=c3MtqtMAAAAJ&hl=en"><img class="btn-svg" alt="Google Scholar" src="img/icons/googlescholar.svg" width="30"></a>
                            <a href="https://github.com/wanyao1992"><img class="btn-svg" alt="Github" src="img/icons/github-circular.svg" width="30"></a>
                            <a href="https://www.linkedin.com/in/yao-wan-980793b6/"><img class="btn-svg" alt="LinkedIn" src="img/icons/linkedin-logo.svg" width="30"></a>
                            <a href="https://twitter.com/wanyao1992"><img class="btn-svg" alt="Twitter" src="img/icons/twitter-social-logotype.svg" width="30"></a>
                          </div>
                        </div>
                     </div>
                  </div>

                  <div class="panel panel-default news">
                      <div class="panel-heading news-heading" style="color: #777777">News</div>
                      <div class="panel-body news-body">
                            
                          <ul style="padding-left: 0px; list-style-type: none;">
                           <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">May, 2025</span> Three papers have been accepted by ICML 2025. Congratulations to Gen, Chenlong and Hailong!</li>
                           <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Jan., 2025</span> Three papers have been accepted by ICLR 2025. Congratulations to Dongping and Siyuan!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Jan., 2025</span> Two papers have been accepted by WWW 2025. Congratulations to Yi!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">May., 2024</span> Two papers have been accepted by ACL 2024 (Findings). Congratulations to Zhangqian and Yihe!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">May., 2024</span> One paper has been accepted by ICML 2024. Congratulations to Dongping!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Mar., 2024</span> Three papers have been accepted by NAACL 2024. Congratulations to Wenting and Dongping!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Mar., 2024</span> Our paper titled "Graph Neural Networks for Vulnerability Detection - A Counterfactual Explanation" has been accepted by ISSTA 2024. Congratulations to Zhaoyang!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Jan., 2024</span> Our paper titled "Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study" has been accepted by SIGMOD 2024. Congratulations to Yang!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Jan., 2024</span> Our paper titled "IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code Completion" has been accepted by FSE 2024</a>. Congratulations to Bolun!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Jan., 2024</span> Our paper titled "NL2Formula: Generating Spreadsheet Formulas from Natural Language Queries" has been accepted by EACL 2024. Congratulations to Wei!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">June 14, 2022</span> Our paper titled "You See What I Want You to See: Poisoning Vulnerabilities in Neural Code Search" has been accepted by <a href="https://2022.esec-fse.org/track/fse-2022-research-papers">ESEC/FSE 2022</a>. Congratulations to Shijie!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Feb 24, 2022</span> Our two papers on source code summarization and generation have been accepted by <a href="https://www.2022.aclweb.org"> ACL 2022 </a>. Congratulations to Juncai and Xin!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Jan 25, 2022</span> Our paper titled "NaturalCC: An Open-Source Toolkit for Code Intelligence" has been accepted by <a href="https://conf.researchr.org/track/icse-2022/icse-2022-demo---demonstrations">ICSE 2022 Demo Track.</a></li>
                            <!-- <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Dec 31, 2021</span> Our paper titled "FedBERT: When Federated Learning Meets Pre-Training" has been accepted by <a href="https://dl.acm.org/journal/tist">TIST 2022</a>. Congratulations to Yishu!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Dec 17, 2021</span> Our paper titled "Cross-Language Binary-Source Code Matching with Intermediate Representations" has been accepted by <a href="https://saner2022.uom.gr">SANER 2022</a>. Congratulations to Yi!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Dec 3, 2021</span> Our paper titled "What Do They Capture? - A Structural Analysis of Pre-Trained Language Models for Source Code" has been accepted by <a href="https://conf.researchr.org/track/icse-2022/icse-2022-papers">ICSE 2022</a>. Congratulations to Wei!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Dec 1, 2021</span> Our paper titled "DANets: Deep Abstract Networks for Tabular Data Processing" has been accepted by <a href="https://aaai.org/Conferences/AAAI-22/">AAAI 2022</a>. Congratulations to Jintai!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Nov 8, 2021</span> Our paper titled "XCode: Towards Cross-Language Code Representation with Large-Scale Pre-Training" has been accepted by <a href="https://dl.acm.org/journal/tosem"> TOSEM 2021 </a>. Congratulations to Zehao!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Oct 20, 2021</span> Our paper titled "Multi-Triage: A Multi-Task Learning Framework for Bug Triage" has been accepted by <a href="https://www.journals.elsevier.com/journal-of-systems-and-software"> JSS 2021 </a>. Congratulations to Thazin!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Sep 19, 2021</span> Our paper titled "Modeling Sequential Listening Behaviors with Attentive Temporal Point Process for Next and Next New Music Recommendation" has been accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046"> IEEE TMM 2021 </a>. Congratulations to Dongjing!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Aug 26, 2021</span> Three papers collaborated with UIC, ZJU are accepted by <a href="https://2021.aclweb.org/"> EMNLP 2021 </a>. Congratulations to Ye, Wenting, and Haiwen!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Aug 18, 2021</span> Received two findings from Tencent and NSFC, respectively. Thanks!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">May 6, 2021</span> Our paper titled "Disentangled Code Representation Learning for Multiple Programming Languages" has been accepted by <a href="https://2021.aclweb.org/"> ACL-IJCNLP 2021 </a>. Congratulations to Jingfeng!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Jan 12, 2021</span> Our paper titled "Enriching Non-Autoregressive Transformer with Syntactic and Semantic Structures for Neural Machine Translation" has been accepted by <a href="https://2021.eacl.org/">EACL 2021</a>. Congratulations to Ye!</li>
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Dec 2, 2020</span> Our paper titled "KG-BART: Knowledge Graph-Augmented BART for Generative Commonsense Reasoning" has been accepted by <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>. Congratulations to Ye!</li> -->
                            <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Nov 28, 2020</span> Our toolkit <a href="https://xcodemind.github.io/">NaturalCC</a> has been released in GitHub, which can be accessed via the <a href="https://xcodemind.github.io/">Homepage</a>.</li>
                            <!-- <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Oct 12, 2020</span> Our paper titled "Cross-Supervised Joint-Event-Extraction with Heterogeneous Information Networks" has been accepted by <a href="https://www.micc.unifi.it/icpr2020/">ICPR 2020</a>. Congratulations to Prof. Wang!</li> -->
                             <!-- <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Sep 22, 2020</span> Our paper titled "A Dual Strategy for Slot-Value Prediction through Reading Comprehension on Multi-Domain Dialog State Tracking" has been accepted by <a href="https://sites.google.com/view/starsem2020/">STARSEM 2020</a>. Congratulations to Jian-Guo!</li> -->
                             <!-- <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Sep 15, 2020</span> Our paper titled "Discriminative Nearest Neighbor Few-Shot Intent Detection by Transferring Natural Language Inference" has been accepted by <a href="https://2020.emnlp.org/">EMNLP 2020</a>. Congratulations to Jian-Guo!</li> -->
                             <!-- <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">Sep 14, 2020</span> I have successfully enrolled HUST as a Lecturer, which has been delayed by the COVID-19.</li> -->
                             <!-- <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">May 29, 2020</span> Our paper titled "FCCA: Hybrid Code Representation for Functional Clone Detection Using Attention Networks" is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=24">Transaction on Reliability</a>.</li> -->
                             <!-- <li><img src="img/icons/right-arrow.svg" width="10">&nbsp;&nbsp;&nbsp;&nbsp;<span class="event-date">March 3, 2020</span> Our paper titled "<a href="#">Reinforcement-Learning-Guided Source Code Summarization via Hierarchical Attention</a>" is accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=32">IEEE Transaction on Software Engineering</a>.</li> -->
                          </ul>
                      </div>
                  </div>
                  <!-- <div class="navbar hidden-xs hidden-sm">
                     <h4>Navigation</h4>
                     <ul style="padding-left: 16px; list-style-type: none;">
                        <li class="li-relaxed"><img src="img/icons/curriculum.svg" width="16">&nbsp;&nbsp;&nbsp;&nbsp;<a href="files/cv.pdf">CV</a></li>
                        <li class="li-relaxed"><img src="img/icons/pencil.svg" width="16">&nbsp;&nbsp;&nbsp;&nbsp;<a href="">Blog (coming soon!)</a></li>
                        <li class="li-relaxed"><img src="img/icons/tools.svg" width="16">&nbsp;&nbsp;&nbsp;&nbsp;<a href="resources.html">Resources</a></li>
                     </ul>
                  </div>
                  <div class="hidden-xs hidden-sm hidden-md">
                     <footer>
                        <p><small>Last updated on <a>Apr 3, 2020</a></small></p>
                     </footer>
                  </div> -->
               </div>
            </div>
            <div class="col-md-8 col-sm-12 col-xs-12 main-body" style="margin-right: -1px"> <!--margin-right for temporal debug-->
               <div>
                  <div class="section">
                     <h3>
                        <a id="about-me" class="anchor" href="#about-me" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link" style="border-left: thick solid #5686b0;padding-left:5px;"></span></a>About Me
                     </h3>
                     <p style="text-align:justify;margin-bottom:12px;">
                       I am currently an Associate Professor with the <a href="http://cs.hust.edu.cn/">College of Computer Science and Technology</a> at <a href="http://www.hust.edu.cn/">Huazhong University of Science and Technology (HUST)</a>, Wuhan, China.
                       Prior to that, I got my Ph.D degree from <a href="http://www.zju.edu.cn/" target="_blank">Zhejiang University</a> in 2019, under the supervision of <a href="https://person.zju.edu.cn/0004274" target="_blank">Prof. Jian Wu</a> and <a href="https://person.zju.edu.cn/zhaozhou" target="_blank">Prof. Zhou Zhao</a>.
                       I have been visiting Shenzhen Research Institute, Chinese University of Hong Kong, China (working with <a href="https://scholar.google.com/citations?user=WPC6ED4AAAAJ&hl=en&oi=ao">Prof. Zibin Zheng</a>) in 2014, University of Technology Sydney, Australia (working with <a href="https://sites.google.com/view/guandong-xu">Prof. Guandong Xu</a>) in 2016, and University of Illinois Chicago, USA (working with <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=en">Prof. Philip S. Yu</a>) in 2018.
                       At HUST, I lead the ONE Lab, dedicated to empowering machines to interact with the physical world through a unified natural language interface—<i>Language + X</i>, where X can be code, vision, tables, etc.
                     </p>
                     <!-- <p>
                        At HUST, I lead the ONE Lab, dedicated to empowering machines to interact with the physical world through a unified natural language interface—Language + X, where X encompasses code, vision, tables, and more. -->
                        <!-- My research interests are mainly focusing on the synergy between Artificial Intelligence and Software Engineering, especially on Natural Language Processing, Programming Languages, and Large Language Models. -->
                     <!-- </p> -->
                    <!-- <p style="text-align:justify;margin-bottom:12px;">
                      During my Ph.D life, I am fortunate to have the following three wonderful experiences hosted by three distinguished professors who have provided me much support, and I am also happy to meet with many wonderful friends and collaborators during these experiences.
                      I have been visiting Shenzhen Research Institute, Chinese University of Hong Kong, China (working with <a href="https://scholar.google.com/citations?user=WPC6ED4AAAAJ&hl=en&oi=ao">Prof. Zibin Zheng</a>) in 2014, University of Technology Sydney, Australia (working with <a href="https://sites.google.com/view/guandong-xu">Prof. Guandong Xu</a>) in 2016, and University of Illinois at Chicago, USA (working with <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=en">Prof. Philip S. Yu</a>) in 2018.
                    </p> -->
                    <p style="text-align:justify;margin-bottom:12px;color:red">
                      (I am looking for <b>highly-motivated</b> under-graduate students with a <b>strong passion</b> to work with me. If interested, please drop me a message by email.)
                    </p>
                    <!-- I obtained my B.Eng. degree in Software Engineering from <a href="http://www.neu.edu.cn/">Northeastern University</a>, Shenyang, China.  -->

                    <!-- <ul>
                      <li>Visting student @ Big Data and Social Computing Lab, University of Illinois at Chicago, USA (Jan. 2018 - Jan. 2019), hosted by Prof. <a href="https://scholar.google.com/citations?user=D0lL1r0AAAAJ&hl=en">Philip S. Yu</a> (ACM/IEEE Fellow)</li>
                      <li>Visting student @ Advanced Analytics Institute, University of Technology Sydney, Australia (Jul. 2016 - Jan. 2017), hosted by Prof. <a href="https://sites.google.com/view/guandong-xu">Guandong Xu</a></li>
                      <li>Visting student @ Shenzhen Research Institute, Chinese University of Hong Kong, China (Feb. 2014 - Sep. 2014), hosted by Prof. <a href="https://scholar.google.com/citations?user=WPC6ED4AAAAJ&hl=en&oi=ao">Zibin Zheng</a></li>
                    </ul> -->
                  </div>

                  <div class="section">
                     <h3>
                        <a id="research-projects" class="anchor" href="#research-projects" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link" style="border-left: thick solid #5686b0;padding-left:5px;"></span></a>Research Highlights
                     </h3>
                     <div class="project-snapshot">
                        <div class="row">
                           <!--<div class="col-md-3 project-logo"></div>-->
                           <div class="figure">
                              <a href="http://xcodemind.github.io"><img class="btn-svg-lg" src="img/logos/c.png" alt="NaturalCC Logo" style="width:70px; height:70px; float:left; margin: 8px 16px 12px 16px"></a>
                              <p style="margin:0px;margin-left:5px;text-align:justify;">
                                <span class="dataset">NaturalCC</span> is an advanced sequence modeling toolkit designed to empower researchers and developers in training custom models for a myriad of software engineering tasks, including but are not limited to code summarization, code generation, code search, and type inference. Our vision is to seamlessly connect the realms of programming language and natural language, leveraging cutting-edge machine learning techniques.
                                <!-- <span style="font-size: 12px">[<a href="pubs/2018-ASE-code-summarization.pdf">ICSE'22 Demo</a>]</span> -->
                                <span style="font-size: 12px">
                                  <a class="btn btn-default btn-xs btn-pub" href="https://arxiv.org/pdf/2012.03225.pdf">
                                  <i class="fa fa-download"></i> arXiv </a>
                                  <a class="btn btn-default btn-xs btn-pub" href="https://github.com/CGCL-codes/naturalcc">
                                  <i class="fa fa-github"></i> Code </a>
                                  <a class="btn btn-default btn-xs btn-pub" href="https://xcodemind.github.io">
                                  <i class="fa fa-newspaper-o"></i> Homepage</a>
                                </span>
                                <!-- is a sequence modeling toolkit that allows researchers and developers to train custom models for many software engineering tasks, e.g., code summarization, code generation, code retrieval, code clone detection, and so on. Our vision is to bridge the gap between programming language and natural language through some machine learning techniques. -->
                                 <!-- <span style="font-size: 12px">[<a href="#">FSE'22</a>, <a href="#"> ICSE'22</a>, <a href="pubs/2018-ASE-code-summarization.pdf">ASE'18</a>, <a href="pubs/2019-ASE-code-retrieval.pdf">ASE'19</a>, <a href="#">TSE'20</a>, <a href="#">ACL'21</a>, <a href="#">EMNLP'21</a>, <a href="#">TOSEM'21</a>]</span> -->
                              </p>
                           </div>
                        </div>
                     </div>

                     <!-- <div class="project-snapshot">
                        <div class="row"> -->
                           <!--<div class="col-md-3 project-logo"></div>-->
                           <!-- <div class="figure">
                              <a href="#"><img class="btn-svg-lg" src="img/logos/scsminer_architecture.jpg" alt="SCSMiner Logo" style="width:70px; height:70px; float:left; margin: 8px 16px 12px 16px"></a>
                              <p style="margin:0px;margin-left:5px;text-align:justify;">
                                <span class="dataset">SCSMiner</span> is a mining system on social coding sites (e.g., GitHub), which integrates social networking and distributed version control in a unified platform to facilitate collaborative developments over the world. It can be applied to software developer recruitment for IT corporations.<span style="font-size: 12px">[<a href="pubs/2018-WWWJ-SCSMiner.pdf">WWWJ'18</a>, <a href="pubs/2018-neurocomputing-cqa.pdf">Neurocomputing'18</a>]</span>
                              </p>
                           </div>
                        </div>
                     </div> -->
                  </div>
                  <div class="section">
                     <h3>
                        <a id="publication" class="anchor" href="#publication" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link" style="border-left: thick solid #5686b0;padding-left:5px;"></span></a>Selected Publications (<a href="https://wanyao.me/publication.html">Full List</a>)
                     </h3>
                     <div class="publication">
                        <h4><i>Language + Code</i></h4>
                     </div>

                     <div class="pub-section">
                        <!-- <h4><i>Conference Proceedings</i></h4> -->
                        <div class="publication">
                           <span class="pubtitle">
                             Dataflow-Guided Neuro-Symbolic Language Models for Type Inference
                           </span><br>
                           <span class="authors">
                             Gen Li, <span class="author-me">Yao Wan*</span>, Hongyu Zhang, Zhou Zhao, Wenbin Jiang, Xuanhua Shi, Hai Jin, Zheng Wang
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>ICML 2025</b>. <i>The Forty-second International Conference on Machine Learning</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b> </a>
                           </span>
                         </div>
                         <div class="publication">
                           <span class="pubtitle">
                             CodeSync: Synchronizing Large Language Models with Dynamic Code Evolution at Scale
                           </span><br>
                           <span class="authors">
                             Chenlong Wang, Zhaoyang Chu, Zhengxiang Cheng, Xuyi Yang, Kaiyue Qiu, <span class="author-me">Yao Wan*</span>, Zhou Zhao, Xuanhua Shi, Hai Jin, Dongping Chen
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>ICML 2025</b>. <i>The Forty-second International Conference on Machine Learning</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b> </a>
                           </span>
                         </div>
                         <div class="publication">
                           <span class="pubtitle">
                             Can Large Language Models Understand Intermediate Representations?
                           </span><br>
                           <span class="authors">
                             Hailong Jiang, Jianfeng Zhu, <span class="author-me">Yao Wan</span>, Bo Fang, Hongyu Zhang, Ruoming Jin, Qiang Guan
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>ICML 2025</b>. <i>The Forty-second International Conference on Machine Learning</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b> </a>
                           </span>
                         </div>
                        <div class="publication">
                           <span class="pubtitle">
                             How to Select Pre-Trained Code Models for Reuse? A Learning Perspective
                           </span><br>
                           <span class="authors">
                             Zhangqian Bi, <span class="author-me">Yao Wan*</span>, Zhaoyang Chu, Yufei Hu, Junyi Zhang, Hongyu Zhang, Guandong Xu and Hai Jin
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>SANER 2025</b>. <i>2025 IEEE International Conference on Software Analysis, Evolution and Reengineering</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-B</b> </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b><span style="color: darkred;">IEEE TCSE Distinguished Paper Award</span></b> </a>
                             <b></b>
                           </span>
                        </div>

                        <div class="publication">
                            <span class="pubtitle">
                               Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit
                            </span><br>
                            <span class="authors">
                               <span class="author-me">Yao Wan</span>, Yang He, Zhangqian Bi, Jianguo Zhang, Hongyu Zhang, Yulei Sui, Guandong Xu, Hai Jin, Philip Yu
                            </span><br>
                            <span class="venuetype"></span><span class="venue"><b>ACM Computing Survey 2024</b>.</span><br>
                            <span class="links btn-group">
                               <a class="btn btn-default btn-xs btn-pub" href="#">
                               <i class="fa fa-download"></i> PDF </a>
                               <a class="btn btn-default btn-xs btn-pub" href="https://arxiv.org/abs/2401.00288">
                               <i class="fa fa-download"></i> arXiv </a>
                            </span>
                        </div>
                        
                        <div class="publication">
                           <span class="pubtitle">
                               You See What I Want You to See: Poisoning Vulnerabilities in Neural Code Search
                           </span><br>
                           <span class="authors">
                               <span class="author-me">Yao Wan</span>, Shijie Zhang, Hongyu Zhang, Yulei Sui, Guandong Xu, Dezhong Yao, Hai Jin, and Lichao Sun
                           </span><br>
                            <span class="venuetype"></span><span class="venue"><b>ESEC/FSE 2022</b>. <i>The 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering.</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="#">
                             <i class="fa fa-download"></i> PDF </a>
                             <!-- <a class="btn btn-default btn-xs btn-pub" href="https://github.com/wanyao1992/mman_public">
                             <i class="fa fa-github"></i> Code </a> -->
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b></a>
                           </span>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                               What Do They Capture? - A Structural Analysis of Pre-Trained Language Models for Source Code
                           </span><br>
                           <span class="authors">
                               <span class="author-me">Yao Wan</span>, Wei Zhao, Hongyu Zhang, Yulei Sui, Guandong Xu and Hai Jin
                           </span><br>
                            <span class="venuetype"></span><span class="venue"><b>ICSE 2022</b>. <i>The 44th ACM/IEEE International Conference on Software Engineering</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="#">
                             <i class="fa fa-download"></i> PDF </a>
                             <!-- <a class="btn btn-default btn-xs btn-pub" href="https://github.com/wanyao1992/mman_public">
                             <i class="fa fa-github"></i> Code </a> -->
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b></a>
                           </span>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                               Multi-Modal Attention Network Learning for Semantic Source Code Retrieval
                           </span><br>
                           <span class="authors">
                               <span class="author-me">Yao Wan</span>, Jingdong Shu, Yulei Sui, Guandong Xu, Zhou Zhao, Jian Wu, Philip S. Yu
                           </span><br>
                            <span class="venuetype"></span><span class="venue"><b>ASE 2019</b>. <i>The 34th ACM/IEEE International Conference on Automated Software Engineering </i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="pubs/2019-ASE-code-retrieval.pdf">
                             <i class="fa fa-download"></i> PDF </a>
                              <a class="btn btn-default btn-xs btn-pub" href="https://github.com/wanyao1992/mman_public">
                              <i class="fa fa-github"></i> Code </a>
                              <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b></a>
                           </span>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                               Improving Automatic Source Code Summarization via Deep Reinforcement Learning
                           </span><br>
                           <span class="authors">
                               <span class="author-me">Yao Wan</span>, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, Philip S. Yu
                           </span><br>
                            <span class="venuetype"></span><span class="venue"><b>ASE 2018</b>. <i>The 33rd ACM/IEEE International Conference on Automated Software Engineering </i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="pubs/2018-ASE-code-summarization.pdf">
                             <i class="fa fa-download"></i> PDF </a>
                              <a class="btn btn-default btn-xs btn-pub" href="https://github.com/wanyao1992/code_summarization_public">
                              <i class="fa fa-github"></i> Code </a>
                              <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b></a>
                           </span>
                        </div>
                        
                        <div class="publication">
                           <h4><i>Language + UI</i></h4>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                             GUI-World: A GUI-oriented Dataset for Multimodal LLM-based Agents
                           </span><br>
                           <span class="authors">
                             Dongping Chen, Yue Huang, Siyuan Wu, Jingyu Tang, Huichi Zhou, Qihui Zhang, Zhigang He, Yilin Bai, Chujie Gao, Liuyi Chen, Yiqiang Li, Chenlong Wang, Yue Yu, Tianshuo Zhou, Zhen Li, Yi Gui, <span class="author-me">Yao Wan*</span>, Pan Zhou, Jianfeng Gao, Lichao Sun
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>ICLR 2025</b>. <i>The Thirteenth International Conference on Learning Representations</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>Top AI Conference</b> </a>
                           </span>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                             UICopilot: Automating UI Synthesis via Hierarchical Code Generation from Webpage Designs
                           </span><br>
                           <span class="authors">
                             Yi Gui, Zhen Li, Zhongyi Zhang, <span class="author-me">Yao Wan*</span>, Dongping Chen, Hongyu Zhang, Yi Su, Bohua Chen, Xing Zhou, Wenbin Jiang, Xiangliang Zhang 
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>WWW 2025 (<span style="color: darkred;">Oral</span>)</b>. <i>The Web Conference 2025</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b> </a>
                           </span>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                              WebCode2M: A Real-World Dataset for Code Generation from Webpage Designs
                           </span><br>
                           <span class="authors">
                              Yi Gui, Zhen Li, <span class="author-me">Yao Wan*</span>, Yemin Shi, Hongyu Zhang, Yi Su, Bohua Chen, Dongping Chen, Siyuan Wu, Xing Zhou, Wenbin Jiang, Hai Jin, Xiangliang Zhang 
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>WWW 2025 (<span style="color: darkred;">Oral</span>)</b>. <i>The Web Conference 2025</i></span><br>
                           <span class="links btn-group">
                              <a class="btn btn-default btn-xs btn-pub" href="">
                              <i class="fa fa-download"></i> PDF </a>
                              <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b> </a>
                           </span>
                        </div>

                        <div class="publication">
                           <h4><i>Language + Table</i></h4>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                             Automated Data Visualization from Natural Language via Large Language Models: An Exploratory Study
                           </span><br>
                           <span class="authors">
                             Yang Wu#, <span class="author-me">Yao Wan#*</span>, Hongyu Zhang, Yulei Sui, Wucai Wei, Wei Zhao, Guandong Xu, Hai Jin
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>SIGMOD 2024</b>. <i>ACM Special Interest Group on Management of Data</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="#">
                             <i class="fa fa-download"></i> PDF </a>
                             <!-- <a class="btn btn-default btn-xs btn-pub" href="https://arxiv.org/abs/2108.04556">
                             <i class="fa fa-download"></i> arXiv </a> -->
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b> </a>
                           </span>
                        </div>


                        <div class="publication">
                           <h4><i>Language + Vision</i></h4>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                             Interleaved Scene Graph for Interleaved Text-and-Image Generation Assessment
                           </span><br>
                           <span class="authors">
                             Dongping Chen, Ruoxi Chen, Shu Pu, Zhaoyi Liu, Yanru Wu, Caixi Chen, Benlin Liu, Yue Huang, <span class="author-me">Yao Wan</span>, Pan Zhou, Ranjay Krishna 
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>ICLR 2025 (<span style="color: darkred;">Spotlight</span>)</b>. <i>The Thirteenth International Conference on Learning Representations</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>Top AI Conference</b> </a>
                           </span>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                             MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark
                           </span><br>
                           <span class="authors">
                             Dongping Chen, Ruoxi Chen, Shilin Zhang, Yinuo Liu, Yaochen Wang, Huichi Zhou, Qihui Zhang, <span class="author-me">Yao Wan*</span>, Pan Zhou, Lichao Sun
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>ICML 2024 (<span style="color: darkred;">Oral</span>)</b>. <i>The Forty-first International Conference on Machine Learning</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="#">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href="https://arxiv.org/pdf/2402.04788">
                             <i class="fa fa-download"></i> arXiv </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b> </a>
                           </span>
                        </div>

                        
                        <div class="publication">
                           <h4><i>Large Language Models</i></h4>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                             DataGen: Unified Synthetic Dataset Generation via Large Language Models
                           </span><br>
                           <span class="authors">
                             Yue Huang, Siyuan Wu, Chujie Gao, Dongping Chen, Qihui Zhang, <span class="author-me">Yao Wan*</span>, Tianyi Zhou, Chaowei Xiao, Jianfeng Gao, Xiangliang Zhang, Lichao Sun
                           </span><br>
                           <span class="venuetype"></span><span class="venue"><b>ICLR 2025</b>. <i>The Thirteenth International Conference on Learning Representations</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>Top AI Conference</b> </a>
                           </span>
                        </div>
                        <div class="publication">
                           <span class="pubtitle">
                             HonestLLM: Toward an Honest and Helpful Large Language Model
                           </span><br>
                           <span class="authors">
                             Chujie Gao, Siyuan Wu, Yue Huang, Dongping Chen, Qihui Zhang, Zhengyan Fu, <span class="author-me">Yao Wan*</span>, Lichao Sun, Xiangliang Zhang
                           </span><br>
                            <span class="venuetype"></span><span class="venue"><b>NeurIPS 2024</b>. <i>The 38th Annual Conference on Neural Information Processing Systems</i></span><br>
                           <span class="links btn-group">
                             <a class="btn btn-default btn-xs btn-pub" href="">
                             <i class="fa fa-download"></i> PDF </a>
                             <a class="btn btn-default btn-xs btn-pub" href="https://arxiv.org/abs/2406.00380">
                               <i class="fa fa-download"></i> arXiv </a>
                             <a class="btn btn-default btn-xs btn-pub" href=""><i class="fa fa-flag-o"></i><b>CCF-A</b> </a>
                           </span>
                        </div>

                      </div>
                  </div>


                  <!-- <div class="section">
                     <h3>
                        <a id="service" class="anchor" href="#services" ria-hidden="true"><span aria-hidden="true" class="octicon octicon-link" style="border-left: thick solid #5686b0;padding-left:5px;"></span></a>Professional Services
                     </h3>
                     <div>
                         <div><img src="img/icons/diamond.svg" width="10">&nbsp;&nbsp;Confenrence PC/Reviewer
                           <ul>
                             <li>ISSTA: 2024; ACL: 2023, 2022,2021; EMNLP: 2023,2022,2021; AAAI: 2022,2021; IJCAI: 2021; SIGKDD: 2024,2023,2022; WSDM: 2022; COLING: 2020; NLPCC: 2020; BESC: 2021, 2020</li>
                           </ul>
                         </div>
                         <div><img src="img/icons/diamond.svg" width="10">&nbsp;&nbsp;Journal Reviewer
                            <ul>
                              <li>TSE: 2021; TKDE: 2021; WWWJ: 2017-2021; TRel: 2020</li>
                            </ul>
                         </div>
                     </div>
                  </div> -->

                  <!-- <div class="section">
                     <h3>
                        <a id="misc" class="anchor" href="#misc" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Miscellaneous
                     </h3>
                     <div>
                        <span><img src="img/icons/diamond.svg" width="10">&nbsp;&nbsp;&nbsp;
                            I was a PhD student of the late <a href="https://www.cs.washington.edu/people/faculty/taskar">Ben Taskar</a>.
                        </span><br>
                        <span><img src="img/icons/diamond.svg" width="10">&nbsp;&nbsp;&nbsp;
                           <a href="http://tcat.cs.washington.edu">The Taskar Center for Accessible Technology (TCAT)</a> was lauched by <a href="https://tcat.cs.washington.edu/people/anat-caspi/">Anat Caspi</a> in November, 2014. I am excited about its mission. Anat's expertise and unique perspective would lead to accessible technologies that could change the life for <a href="https://tcat.cs.washington.edu/community/">many</a>.
                        </span><br>
                        <span><img src="img/icons/diamond.svg" width="10">&nbsp;&nbsp;&nbsp;
                           I'm fascinated by different kinds of puzzles. At some point I tried to make a few: <a href="misc/sea_virus.pdf">Sea Virus</a>, <a href="misc/chocolate_crush.pdf">Chocolate Crush</a>.
                        </span>
                     </div>
                  </div> -->
                  <!-- <div class="section hidden-md hidden-lg hidden-xl">
                     <h3>
                        <a id="navigation" class="anchor" href="#navigation" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Navigation
                     </h3>
                     <ul style="padding-left: 16px; list-style-type: none;">
                        <li class="li-relaxed"><img src="img/icons/curriculum.svg" width="18">&nbsp;&nbsp;&nbsp;&nbsp;<a href="files/cv.pdf">CV</a></li>
                        <li class="li-relaxed"><img src="img/icons/pencil.svg" width="16">&nbsp;&nbsp;&nbsp;&nbsp;<a href="">Blog (coming soon!)</a></li>
                        <li class="li-relaxed"><img src="img/icons/tools.svg" width="16">&nbsp;&nbsp;&nbsp;&nbsp;<a href="resources.html">Resources</a></li>
                     </ul>
                  </div> -->
               </div>
            </div>
         </div>

         <!-- <div>
            <div style="display: inline-block;">
               <footer>
                  <p><small>Last updated on <a>Apr 3, 2020</a></small></p>
               </footer>
            </div>
         </div> -->
        </div>
      </div>
  </div>
  <!-- ======= Footer ======= -->
  <footer id="footer">
      <div class="box">
         <div class="left">
            <div class="flex icon-name">
               <div class="icon">
                  <svg xmlns="http://www.w3.org/2000/svg" viewBox="-40 -60 80 100">
                     <style>
                       .bubble {
                         animation: float 2s ease-out both infinite var(--delay);
                       }
                       @keyframes float {
                         0% {
                           opacity: 0;
                         }
                         50% {
                           transform: translateY(0);
                           opacity: 0;
                         }
                         75% {
                           opacity: 1;
                         }
                         100% {
                           opacity: 0;
                           transform: translateY(-40px);
                         }
                       }
                     </style>
                     <g fill="currentColor" opacity="0.5">
                       <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 0.1s"></circle>
                       <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 0.4s"></circle>
                       <circle class="bubble" cx="0" cy="-10" r="3" style="--delay: 1.1s"></circle>
                     </g>
                     <path fill="#38bdf8" d="
                         M 0 -22.5
                         L -19.5 -11.25
                         L -19.5 11.25
                         L 0 22.5
                         L 19.5 11.25
                         L 19.5 -11.25
                         z
                       "></path>
                     <path fill="#bae6fd" d="
                         M 0 -22.5
                         L -19.5 -11.25
                         L 0 0
                         L 19.5 -11.25
                         z
                       "></path>
                     <path fill="none" stroke="currentColor" stroke-width="5" d="
                         M -18 -53
                         L -10 -53
                         L -10 -29.2
                         L -30.3 -17.5
                         L -30.3 17.5
                         L 0 35
                         L 30.3 17.5
                         L 30.3 -17.5
                         L 10 -29.2
                         L 10 -53
                         L 18 -53
                       "></path>
                   </svg>
               </div>
               <div class="name">ONE Lab</div>
            </div>
          </div>
          <div class="right">
            <div class="address item">
               <i class="fa fa-map-marker" aria-hidden="true"></i>
               1037 Luoyu Road, Wuhan, Hubei, China
            </div>
            <div class="email item">
               <i class="fa fa-envelope" aria-hidden="true"></i>
               <a href="mailto:wanyao{AT}hust.edu.cn" style="font-family: Lato, sans-serif; font-weight: 400">wanyao@hust.edu.cn</a>
            </div>
          </div>
      </div>
  </footer>
  <!-- End Footer -->
      <script src="javascripts/jquery-3.3.1.min.js"></script>
      <script src="lib/bootstrap-3.3.7-dist/js/bootstrap.min.js"></script>
      <script src="javascripts/scale.fix.js"></script>
      <script src="javascripts/inline-svg.js"></script>
      <script>
         document.body.style.zoom="110%";
         $('.btn-pub').mouseup(function() { this.blur() })

         $(function () {
            $('[data-toggle="tooltip"]').tooltip()
         })
      </script>
   </body>

</html>
